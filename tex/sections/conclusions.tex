\section{Conclusions}\label{sec:conclusions}

This paper presented an interactive augmented reality teaching system capable of displaying assembly instructions, perform object recognition and do projection mapping for helping the final visual inspection phase. The system was tested with the assembly of a starter engine, in which the operator read the textual and video instructions for each step (moving between steps using the projected \gls{gui} that was being monitored by the 3D perception system) and then validated the assembly process by analyzing the overlap between the final product geometry and the outline of the expected 3D model that was projected into the environment (after the perception system performed 6 \gls{dof} pose estimation of the assembled product).

Several improvements were made to the Gazebo simulator in order to make 3D scene rendering for accurate projection mapping, such as modeling of the projector intrinsic parameters using the \gls{opengl} projection matrix and addition of efficient display of dynamic images and videos. This provided the fundamental rendering and projection capabilities that coupled with our 3D perception system resulted in a more effective and intuitive approach for teaching new skills to operators (in relation to the traditional user manuals), that requires shorter teaching sessions which do not need the supervision of an experienced tutor.

The presented immersive teaching system can be improved further by adding an assembly analysis module for monitoring what the operator is doing in order to provide contextual help (such as detecting that the current component was mounted correctly and projecting the next part that the operator needs to assemble) and also alert for possible mistakes done by the operator during assembly. This would allow continuous analysis and quality control of the assembly process that would reduce the time required for the detection and correction of assembly problems.
