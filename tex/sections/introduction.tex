\section{Introduction}\label{sec:introduction}

Teaching humans new manufacturing skills or advanced assembly / maintenance operations can be a long and error prone process that requires reading extensive manuals and a period of tutoring in which they are trained by field experts. This teaching period can be shortened and done without the need of other workers by relying on immersive \gls{hmi} teaching systems that are able to transmit the knowledge more effectively using step by step instructions containing text and video along with visual cues showing the work areas and pick / place locations tagged with contextual help. Moreover, when coupled with active perception systems that can detect the assembly objects and what the operator is doing, the teaching system can also act as a supervisor, alerting the operator when a mistake is made or when a damaged component needs to be replaced. This approach to skill transfer using immersive \glspl{hmi} along with dynamic feedback can speedup and improve the effectiveness of the training sessions while also giving continuous quality control, allowing to reduce the cost and time of product assembly, repair and maintenance.

With these goals in mind, an augmented reality teaching system was developed that relies on projection mapping techniques for augmenting the operator workspace with contextual assembly instructions detailing the operations and tools that are required to assemble a given product. Each step contains textual descriptions of the operations that the operator needs to perform and is accompanied by a video in which an expert tutor is performing the described task. The \gls{hmi} interface monitors the projected \gls{gui} and analyzes the 3D sensor data to detect when the operator uses the instruction navigation buttons (to move to the first, previous, next and last instruction step) or wants to interact with the video (play, pause or seek). Moreover, for helping the operator perform the assembly validation and quality assessment faster, the last assembly step includes a visual inspection phase in which the 6 \gls{dof} pose of the assembled object is computed using a geometric feature matching approach followed by dense point cloud registration refinement in order to be able to project with high accuracy the 3D model of the expected geometry into the final assembled product.

In the following section it will be given a brief overview of the augmented reality systems that were developed over the years for teaching operators how to perform assembly, maintenance and repair operations. Then in \cref{sec:sar} it will be introduced the mathematical modeling of the \gls{dlp} projector used along with the calibration required for accurate 3D rendering and projection. Later on, \cref{sec:human-machine-interaction} will describe the \gls{hmi} developed for allowing the operator to navigate between the assembly operations. Given the lack of \gls{cad} models of the starter motor used, \cref{sec:object-reconstruction} will describe how the 3D model was retrieved using a structured light system. Then in \cref{sec:pose-estimation} it will be presented the processing pipeline of the developed 6 \gls{dof} object pose estimation system. Finally, \cref{sec:training} will present the results of a training session while \cref{sec:conclusions} will summarize the conclusions and present possible future work.
